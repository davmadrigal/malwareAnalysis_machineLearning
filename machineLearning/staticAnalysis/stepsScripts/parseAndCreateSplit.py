import sys
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer

# Lee el archivo y obtén las columnas
#features = pd.read_csv('staticfeature.txt', sep=':', header=None)
#col_names =[x.strip() for x in features[1].tolist()]


PATH = "./DatasetReducedBalanced.csv"
# la primera fila es el encabezado
#data = pd.read_csv(PATH, header=0, names=col_names)

def loadData(path=PATH):
  return pd.read_csv(path)


data = loadData()
#data = loadData()
# obtener el tipo de datos
data.info()

print(data.head())


# eliminar el nombre, primera columna
data_noName = data.drop(data.columns[0], axis=1)
data_noName.info()
print(data_noName.head())
# ver si hay valores nulos

#print(data_noName.isnull().sum)

# ver si hay valores vacios ''
#mostrar las columnas 76,77 y 89 columnas con valores '', por eso son de tipo object
data_subset = data_noName.iloc[:, 75]
data_subset1 = data_noName.iloc[:, 76]
data_subset2 = data_noName.iloc[:, 88]

valores_unicos = data_subset.unique()
print(data_subset.unique())
print(data_subset1.unique())
print(data_subset2.unique())

# cuantos valores hay ''
conteo_valores_vacios = (data_noName.iloc[:, 75] == '').sum()
conteo_valores_vacios1 = (data_noName.iloc[:, 76] == '').sum()
conteo_valores_vacios2 = (data_noName.iloc[:, 88] == '').sum()
print(conteo_valores_vacios)
print(conteo_valores_vacios1)
print(conteo_valores_vacios2)

# reemplazar '' con 0
data_noName_noEmpty = data_noName.iloc[:,:].replace('', '0')
# Convertir las columnas al tipo numérico
data_noName_noEmpty= data_noName_noEmpty.iloc[:,:].apply(pd.to_numeric, errors='coerce')

data_noName_noEmpty.info()

# Ahora todos los datos son de tipo numerico, gracias a este preprocesado. No hay ninguno de tipo categorico (el preprocesado en el dynamico sera cambiar el tipo de label, podria ser haciendo esto
# df['Attrition'].replace(['Yes','No'],[1,0],inplace=True)

# Lo mejor seria hacer un split para sacar el train set y test set





x_train,x_test,y_train,y_test = train_test_split(data_noName_noEmpty, data_noName_noEmpty['2'], test_size=0.3, random_state=42)

train_data = pd.concat([x_train , y_train], axis = 1)
test_data = pd.concat([x_test , y_test], axis = 1)
print(train_data.head())
print(test_data.head())


# ejemplo web
#train, test = train_test_split(data, test_size=0.2, random_state=22)

# csv separados
train_data.to_csv('staticAnalisys_train.csv', index=False)
test_data.to_csv('staticAnalisys_test.csv', index=False)

# despues, aplicarmos el simpleInputer
# el normalize
# metemos una pipeline

# y seleccionamos un modelo
