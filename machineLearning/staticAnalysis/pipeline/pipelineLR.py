import sys
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from graphviz import Source
from sklearn.tree import export_graphviz
from sklearn.svm import LinearSVC
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report,precision_score, recall_score, f1_score, roc_curve
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB



#PATH = "./DatasetProposed.csv"
#PATH = "./DatasetReducedBalanced.csv"
#PATH = "./DatasetAll.csv"
PATH = "./DatasetMasGoodware.csv"

# Read the file
def loadData(path=PATH):
  return pd.read_csv(path)


data = loadData()
# Get data type


# Remove the first columndd. Binary name
data_noName = data.drop(data.columns[0], axis=1)

# replace '' with 0
data_noName_noEmpty = data_noName.iloc[:,:].replace('', '0')
# Transform columns to numeric type. Algorithms don't know how to work with object types
data_noName_noEmpty= data_noName_noEmpty.iloc[:,:].apply(pd.to_numeric, errors='coerce')

data_noName_noEmpty.info()

# split the data by target, column[2] 0 goodware, 1 malware
x_train,x_test,y_train,y_test = train_test_split(data_noName_noEmpty, data_noName_noEmpty['2'], test_size=0.3, random_state=42)

num_attribs = list(x_train)

num_pipeline = Pipeline([
        ('imputer', SimpleImputer(strategy="median")),
    ])

full_pipeline = ColumnTransformer([
        ("num", num_pipeline, num_attribs)
    ])

data_prepared = full_pipeline.fit_transform(x_train)

# Logistic Regression, crear el modelo
log_reg = LogisticRegression(solver="newton-cg", C=1, random_state=42)

log_reg.fit(data_prepared, y_train)

print()
print("##### RESULTS LGR  #####")
print()
print("Model Coefficients: ", log_reg.coef_)
print("Model Intercept: ",log_reg.intercept_)

data_prepared_test = full_pipeline.transform(x_test)

# Predict responses
print("##### RESULTS LGR: PREDICTIONS  #####")
pred = log_reg.predict(data_prepared_test)
prediction = list(map(round, pred))

# Accuracy score
print('Test accuracy LGR= ', accuracy_score(y_test, prediction))

print("##### RESULTS LGR: MATRIX CONFUSION  #####")
# Confusion matrix
cm = confusion_matrix(y_test, prediction)
print ("Confusion Matrix LGR: ", cm)

fig, ax = plt.subplots(figsize=(12, 12))
ax.imshow(cm, cmap='Pastel1')
ax.grid(False)
ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted Goodware(0)', 'Predicted Malware(1)'))
ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual Goodware(0)', 'Actual Malware(1)'))
ax.set_ylim(1.5, -0.5)

for i in range(2):
    for j in range(2):
        ax.text(j, i, cm[i, j], ha='center', va='center', color="red")
plt.show()


print("##### RESULTS LGR: REPORTS  #####")
print(classification_report(y_test, prediction, digits=5))
print("precision score: ", precision_score(y_test, prediction))
print("recall score: ", recall_score(y_test, prediction))
print("f1_score: ", f1_score(y_test, prediction))

fpr, tpr, thresholds = roc_curve(y_test, prediction)


def plot_roc_curve(fpr, tpr, label=None):
    plt.plot(fpr, tpr, linewidth=2, label=label)
    plt.plot([0, 1], [0, 1], 'k--')
    plt.axis([0, 1, 0, 1])
    plt.xlabel('FPR', fontsize=16)
    plt.ylabel('TPR', fontsize=16)
    plt.grid(True)

plt.figure(figsize=(8, 6))
plot_roc_curve(fpr, tpr)
plt.show()
